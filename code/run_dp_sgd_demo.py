#!/usr/bin/env python3
"""

set up:
python run_dp_sgd_demo.py
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import logging
import sys
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_demo_data():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
    logger.info("åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
    
    # ç”Ÿæˆéšæœºæ•°æ®
    X = torch.randn(200, 128)  # 200ä¸ªæ ·æœ¬ï¼Œ128ç»´ç‰¹å¾
    y = torch.randint(0, 2, (200,))  # äºŒåˆ†ç±»æ ‡ç­¾
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataset = TensorDataset(X, y)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    logger.info(f"æ•°æ®åˆ›å»ºå®Œæˆ: {len(dataset)} ä¸ªæ ·æœ¬")
    return dataloader

def create_demo_model():
    """åˆ›å»ºæ¼”ç¤ºæ¨¡å‹"""
    logger.info("åˆ›å»ºæ¼”ç¤ºæ¨¡å‹...")
    
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    base_model = nn.Sequential(
        nn.Linear(128, 64),
        nn.ReLU(),
        nn.Dropout(0.1),
        nn.Linear(64, 2)
    )
    
    # åˆ›å»ºåŒæ¨¡å—LoRAæ¨¡å‹
    try:
        from code.dual_lora_adapter import create_dual_lora_model
        dual_lora_model = create_dual_lora_model(
            base_model=base_model,
            global_rank=8,
            local_rank=4,
            fusion_method="weighted_sum"
        )
        logger.info("åŒæ¨¡å—LoRAæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        return dual_lora_model
    except ImportError as e:
        logger.error(f"å¯¼å…¥åŒæ¨¡å—LoRAæ¨¡å—å¤±è´¥: {e}")
        logger.info("ä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œæ¼”ç¤º...")
        return base_model

def demo_dp_sgd_training():
    """æ¼”ç¤ºDP-SGDè®­ç»ƒ"""
    logger.info("=" * 60)
    logger.info("DP-SGDè®­ç»ƒæ¼”ç¤º")
    logger.info("=" * 60)
    
    try:
        # å¯¼å…¥DP-SGDæ¨¡å—
        from code.dp_sgd_engine import create_dp_sgd_config, create_dual_lora_dp_trainer
        from code.dual_lora_dp_trainer import DualLoRADPTrainer
        
        # åˆ›å»ºæ•°æ®å’Œæ¨¡å‹
        dataloader = create_demo_data()
        model = create_demo_model()
        
        # åˆ›å»ºDP-SGDé…ç½®
        dp_config = create_dp_sgd_config(
            epsilon=1.0,
            delta=1e-5,
            max_grad_norm=1.0,
            apply_to_global=True,
            apply_to_local=False,
            global_noise_scale=1.0,
            local_noise_scale=0.5
        )
        
        logger.info(f"DP-SGDé…ç½®: Îµ={dp_config.epsilon}, Î´={dp_config.delta}")
        
        # åˆ›å»ºDP-SGDè®­ç»ƒå™¨
        trainer = DualLoRADPTrainer(model, dp_config)
        
        # è®­ç»ƒæ¨¡å‹
        logger.info("å¼€å§‹DP-SGDè®­ç»ƒ...")
        training_history = trainer.train(dataloader, num_epochs=3)
        
        # è¯„ä¼°æ¨¡å‹
        logger.info("è¯„ä¼°æ¨¡å‹...")
        eval_results = trainer.evaluate(dataloader)
        
        # æ‰“å°ç»“æœ
        logger.info("=" * 40)
        logger.info("è®­ç»ƒç»“æœ:")
        logger.info(f"æœ€ç»ˆå‡†ç¡®ç‡: {eval_results['accuracy']:.4f}")
        logger.info(f"æœ€ç»ˆæŸå¤±: {eval_results['loss']:.4f}")
        
        # æ‰“å°éšç§çŠ¶æ€
        privacy_status = trainer.get_privacy_status()
        logger.info("éšç§çŠ¶æ€:")
        logger.info(f"  æ¶ˆè€—çš„éšç§é¢„ç®—: Îµ={privacy_status['consumed_epsilon']:.4f}")
        logger.info(f"  å‰©ä½™éšç§é¢„ç®—: Îµ={privacy_status['remaining_epsilon']:.4f}")
        logger.info(f"  å™ªå£°ä¹˜æ•°: {privacy_status['noise_multiplier']:.4f}")
        
        return True
        
    except ImportError as e:
        logger.error(f"å¯¼å…¥DP-SGDæ¨¡å—å¤±è´¥: {e}")
        logger.info("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—éƒ½å·²æ­£ç¡®å®‰è£…")
        return False
    except Exception as e:
        logger.error(f"DP-SGDè®­ç»ƒæ¼”ç¤ºå¤±è´¥: {e}")
        return False

def demo_privacy_analysis():
    """æ¼”ç¤ºéšç§åˆ†æ"""
    logger.info("=" * 60)
    logger.info("éšç§åˆ†ææ¼”ç¤º")
    logger.info("=" * 60)
    
    try:
        from code.dp_sgd_engine import create_dp_sgd_config, PrivacyAccountant
        
        # æµ‹è¯•ä¸åŒéšç§é¢„ç®—çš„é…ç½®
        privacy_configs = [
            {'epsilon': 0.1, 'name': 'é«˜éšç§ä¿æŠ¤'},
            {'epsilon': 1.0, 'name': 'ä¸­ç­‰éšç§ä¿æŠ¤'},
            {'epsilon': 10.0, 'name': 'ä½éšç§ä¿æŠ¤'},
        ]
        
        logger.info("éšç§é¢„ç®—åˆ†æ:")
        logger.info("-" * 60)
        logger.info(f"{'é…ç½®':<15} {'Îµ':<8} {'å™ªå£°ä¹˜æ•°':<12} {'éšç§å¼ºåº¦':<12}")
        logger.info("-" * 60)
        
        for config in privacy_configs:
            # åˆ›å»ºéšç§è®¡ç®—å™¨
            accountant = PrivacyAccountant(config['epsilon'], 1e-5)
            
            # è®¡ç®—å™ªå£°ä¹˜æ•°
            noise_multiplier = accountant.compute_noise_multiplier(
                target_epsilon=config['epsilon'],
                target_delta=1e-5,
                num_steps=100,
                batch_size=32,
                total_samples=1000
            )
            
            # è®¡ç®—éšç§å¼ºåº¦ï¼ˆå™ªå£°ä¹˜æ•°çš„å€’æ•°ï¼‰
            privacy_strength = 1.0 / noise_multiplier if noise_multiplier > 0 else float('inf')
            
            logger.info(f"{config['name']:<15} {config['epsilon']:<8.1f} "
                       f"{noise_multiplier:<12.4f} {privacy_strength:<12.4f}")
        
        logger.info("-" * 60)
        logger.info("è¯´æ˜: å™ªå£°ä¹˜æ•°è¶Šå°ï¼Œéšç§ä¿æŠ¤è¶Šå¼º")
        
        return True
        
    except ImportError as e:
        logger.error(f"å¯¼å…¥éšç§åˆ†ææ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"éšç§åˆ†ææ¼”ç¤ºå¤±è´¥: {e}")
        return False

def demo_federated_aggregation():
    """æ¼”ç¤ºè”é‚¦èšåˆ"""
    logger.info("=" * 60)
    logger.info("è”é‚¦èšåˆæ¼”ç¤º")
    logger.info("=" * 60)
    
    try:
        from code.dual_lora_aggregator import DualLoRAAggregator
        
        # åˆ›å»ºæ¨¡å‹
        model = create_demo_model()
        
        # åˆ›å»ºå¸¦DP-SGDçš„èšåˆå™¨
        dp_config = {
            'enabled': True,
            'epsilon': 1.0,
            'delta': 1e-5,
            'max_grad_norm': 1.0,
            'enable_secure_aggregation': True,
            'aggregation_noise_scale': 0.8
        }
        
        aggregator = DualLoRAAggregator(
            model=model,
            enable_dp_sgd=True,
            dp_config=dp_config
        )
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„å®¢æˆ·ç«¯å‚æ•°
        client_models = []
        for i in range(3):
            model_state = {}
            for name, param in model.named_parameters():
                if 'global_lora_A' in name or 'global_lora_B' in name:
                    model_state[name] = torch.randn_like(param) + i * 0.1
                else:
                    model_state[name] = param.clone()
            client_models.append(model_state)
        
        # å‡†å¤‡èšåˆä¿¡æ¯
        agg_info = {
            "client_feedback": [
                (i, (100, model_state)) for i, model_state in enumerate(client_models)
            ]
        }
        
        # æ‰§è¡Œèšåˆ
        logger.info("æ‰§è¡Œå¸¦éšç§ä¿æŠ¤çš„è”é‚¦èšåˆ...")
        aggregated_params = aggregator.aggregate(agg_info)
        
        logger.info(f"èšåˆå®Œæˆ: {len(aggregated_params)} ä¸ªå‚æ•°")
        
        # æ£€æŸ¥å…¨å±€å‚æ•°
        global_param_count = sum(1 for key in aggregated_params.keys() 
                               if 'global_lora_A' in key or 'global_lora_B' in key)
        logger.info(f"å…¨å±€å‚æ•°æ•°é‡: {global_param_count}")
        
        return True
        
    except ImportError as e:
        logger.error(f"å¯¼å…¥è”é‚¦èšåˆæ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"è”é‚¦èšåˆæ¼”ç¤ºå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("FedSA-LoRA-Dual DP-SGDæ¼”ç¤ºç¨‹åº")
    logger.info("å‚è€ƒ: IMPROVING LORA IN PRIVACY-PRESERVING FEDERATED LEARNING")
    logger.info("=" * 80)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import torch
        import numpy as np
        logger.info("âœ“ PyTorchå’ŒNumPyå·²å®‰è£…")
    except ImportError as e:
        logger.error(f"âœ— ç¼ºå°‘ä¾èµ–: {e}")
        return
    
    # è¿è¡Œæ¼”ç¤º
    demos = [
        ("DP-SGDè®­ç»ƒæ¼”ç¤º", demo_dp_sgd_training),
        ("éšç§åˆ†ææ¼”ç¤º", demo_privacy_analysis),
        ("è”é‚¦èšåˆæ¼”ç¤º", demo_federated_aggregation),
    ]
    
    success_count = 0
    total_count = len(demos)
    
    for demo_name, demo_func in demos:
        logger.info(f"\nå¼€å§‹ {demo_name}...")
        try:
            if demo_func():
                logger.info(f"âœ“ {demo_name} å®Œæˆ")
                success_count += 1
            else:
                logger.error(f"âœ— {demo_name} å¤±è´¥")
        except Exception as e:
            logger.error(f"âœ— {demo_name} å‡ºé”™: {e}")
    
    # æ€»ç»“
    logger.info("\n" + "=" * 80)
    logger.info("æ¼”ç¤ºæ€»ç»“:")
    logger.info(f"æˆåŠŸ: {success_count}/{total_count}")
    
    if success_count == total_count:
        logger.info("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºéƒ½æˆåŠŸå®Œæˆï¼")
        logger.info("\næ¥ä¸‹æ¥ä½ å¯ä»¥:")
        logger.info("1. è¿è¡Œå®Œæ•´ç¤ºä¾‹: python example_dp_sgd.py")
        logger.info("2. è¿è¡Œæµ‹è¯•: python test_dp_sgd.py")
        logger.info("3. æŸ¥çœ‹é…ç½®: cat dual_lora_config.yaml")
        logger.info("4. é˜…è¯»æ–‡æ¡£: README.md")
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ¼”ç¤ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–å’Œé…ç½®")
        logger.info("\næ•…éšœæ’é™¤:")
        logger.info("1. ç¡®ä¿æ‰€æœ‰Pythonæ–‡ä»¶éƒ½åœ¨åŒä¸€ç›®å½•")
        logger.info("2. æ£€æŸ¥PyTorchç‰ˆæœ¬å…¼å®¹æ€§")
        logger.info("3. æŸ¥çœ‹é”™è¯¯æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")

if __name__ == "__main__":
    main()
